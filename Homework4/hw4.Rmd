---
title: "R Notebook"
output: html_notebook
---


```{r}
library(car)
library(dummies)
library(corrplot)
library(knitr)
library(ggplot2)
library(CCA)
```

# Ejercicio 4: Análisis CCA a mano

En este ejercicio del libro Wishern, analizaremos la estructura de correlaciones canónicas de un decatlón.

A continuación mostrareos las estructura de las correlaciones entre las variables. Vemos  que las relaciones entre las varriables son fuertes salvo el fondo de los 1500 metros (excepto con el salto).
```{r}
#table
df_r <- read.csv('E9-6.csv') 
R <- as.matrix(df_r)
#corrplot
corrplot(R)


```

##CCA Analisis para un subconjunto de variables

Se analizarán las relaciones entre _100m_, _400m_, _salto_ contra _disco_, _javalina_, _lanzamiento de bala_.

Las primeras variables canónicas muestran una correlación canónica $\rho$ del 44%. Se puede inferir de los _loadings_ de U y V que las relaciones son proporcionales entre las variables origniles salvo para los _400m_; los que mayor peso tienen son el lanzamiento de bala y el salto. 
```{r}
#subset
l_subset1 <- c(1,5,2)
l_subset2 <- c(7,9,3)

#sets
R1 <- R[l_subset1,l_subset1]
R2 <- R[l_subset2,l_subset2]
R12 <- R[l_subset1, l_subset2]
R21 <- R[l_subset2, l_subset1]

#cors
A <- solve(R1) %*% R21 %*% solve(R2) %*% R12
B <- solve(R2) %*% R12 %*% solve(R1) %*% R21
sA <- eigen(A)
sB <- eigen(B)

#cca
#corrs
cat("Correlaciones\n")
sqrt(sA$values)

cat("U1\n")
sA$vectors[,1]

cat("V1\n")
sB$vectors[,1]


```

# Ejercicio 5: Datos marketing.

```{r download_dbb}
#descargar BDD
temp <- tempfile()
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip", temp)
W <- read.csv(unz(temp, "bank-full.csv"), header=T, sep=";")


```

El objetivo del concurso es _predecir_ si un usuario se va a inscribir o no a un depósito a plazo. Sin embargo haremos un análisis entre las variables.

Vemos que se pueden agrupar en cuatro conjuntos:

1. Atributos físicos
2. Banco
3. Campaña pasada
4. Miscelanea

Creemos que es de mayor interés ver la relación entre el conjunto de variables de _atributos físicos_ y _campaña pasada_ como tanmbién de _banco_ con _campaña pasada_. Esto debido a que el objetivo primordial del análisis es ver si habrá o no inscripción de depósito a plazo, así que veremos cómo se relacionan este conjunto de conjuntos de variabes con las campañas, para poder predecir la relación entre estas y el performance de la próxima campaña. 

Al tener demasiadas variables categóricas con varias codificaciones, resumiremos las variables a las siguientes:

1. job: 

- high:
- medium:
- low:

2. marital:

- married
- not_married

3. education:

- grad
- non_grad

4. conact:
- yes
- no

5. day & month: to-numeric: Day of the year. 

```{r tidydata}
#modules

to_date <- function(day, month){
  day <- as.numeric(as.character(day))
  month <- as.numeric(as.character(month))
  #month has 30 days
  days <- (month - 1) * 30 + day
  
  return(days)
}


#main
df_main <- W

#recode job
recods_job <- "c('admin.','management','entrepreneur')='high'; c('student','self-employed','retired')='medium'; else='low'"
df_main$job <- recode(df_main$job, recods_job)

#recode marital
recods_marital <- "c('divorced','single')='not_married'"
df_main$marital <-  recode(df_main$marital, recods_marital)

#recode education
recods_ed <- "'tertiary'='grad';else='non_grad'"
df_main$education <-recode(df_main$education, recods_ed)

#recode contact
recode_cont <- "c('cellular','telephone')='1';else='0'"
df_main$contact <- recode(df_main$contact, recode_cont)

#date transformation
recode_month <- "'apr'='4'; 'aug'='8'; 'dec'='12'; 'feb'='2'; 'jan'='1'; 'jul'='7'; 'jun'='6'; 'mar'='3'; 'may'='5'; 'nov'='11'; 'oct'='10'; 'sep'='9'"
df_main$month <- recode(df_main$month, recode_month)
df_main$days <- mapply(FUN = to_date, df_main$day, df_main$month)

#poutcome 
df_main$poutcome <- ifelse( df_main$poutcome == 'success',1,0)


```


Primero veamos como se relacionan las variables

## CCA Atributos físicos vs Campaña pasada

```{r}
#create dumms
create_dums <- function(df, cols){
  #create dumms
  for (categ in cols){
  df <- cbind(df, dummy(df[,categ], sep = '_'))
  }
  
  #delete old cols
  df[,cols] <- NULL
  
  #delete one dummie column to avoid colineality
  df[,'df1_low'] <- NULL
  df[,'df1_not_married'] <- NULL
  df[,'df1_non_grad'] <- NULL
  
  return(df)
}

#### MAIN

#personal atributes
pers_set <- c('age','job','marital','education')
past_campgn_set <- c('contact','days','duration','poutcome')


#select variables
df1 <- df_main[,cbind(pers_set, past_campgn_set)]

#create dummies
#dummies for personal atributes
dumm_cols <- c('job','marital','education')
df1 <- create_dums(df1, dumm_cols)

#cols to numeric
df1[,'contact'] <- as.numeric(as.character(df1[,'contact']))



```

Vemos que la estructura de correlaciones es muy suave entre las variables de la campaña pasada y los atributos físicos.

```{r}
R1 <- cor(df1, method = 'pearson')
corrplot(R1, method = 'color', type = 'upper')
corrplot(R1, method = 'number', type = 'upper')




```

Vemos que las correlaciones entre las variables son muy bajas, por lo que un análisis de correlación canónica es poco descriptivo. Las únicas variables que se relacionan entre si son: 
- empleo_alto: empleo_mediano, casado, si tiene eduación alta
- edad: si está casado, tipo de empleo, si está graduado
- contacto: con el ouutcome pasado

Sin embargo, haremos un intento por ver la relación entre ellas.

## Análisis de CCA

_NOTA_:
Curiosamente los outputs de _cancor_ , _cc_ y la formulación directa por eigenvalores y eigenvectores da muy distinta. A continuación se mostrarán los resultados. 
```{r load_df1}
# set sets
fa_lis <- c('age','df1_high','df1_medium','df1_married','df1_grad')
fa_matrix <- df1[,fa_lis]

pc_lis <- c('contact','days','duration','poutcome')
pc_matrix <- df1[,pc_lis]
```


```{r CCA types}
#CCA analisis
cca1 <- cancor(x = fa_matrix, y = pc_matrix, xcenter = FALSE, ycenter = FALSE) 
cca2 <- cc(fa_matrix, pc_matrix)
# cca3
S <- cov(df1)
Sxx <- S[1:5,1:5]
Syy <- S[6:9,6:9]
Sxy <- S[1:5,6:9]
Syx <- t(Sxy)

#  A and B
A <- solve(Syy) %*%  Syx %*% solve(Sxx) %*% Sxy
sA <- eigen(A)
sqrt(sA$values)

B <- solve(Sxx) %*% Sxy %*% solve(Syy) %*% Syx
sB <- eigen(B)
corCCA3 <- sqrt(sB$values)

```


Veamos las correlaciones canónicas para cada uno de los paquetes:
```{r CCAcorrs}
cca1$cor
cca2$cor
corCCA3

```

Observamos que _cancor_ muestra una $\rho_{1} = $ `r cca1$cor[1]` que es altísima a comparación de las demás.

La correlación canónica más realista es la del paquete _CCA_.  En este resultado vemos que la correlación máxima lineal entre las variables del primer y segundo conjunto es del 17%. Por lo que es muy baja la relación entre un conjutno y otro, así que cualquier inferencia entre estas mismas debe tomarse con precacuión.

- $COR(U_{k}, V_{j}) y COR(U_{k}, X_{j}^{i})$

Observemos las correlaciones entre $U = X^{(1)}B$ y $V = X^{(2)}A$
```{r}
# canonical variables
U1 <- as.matrix(fa_matrix)  %*% as.matrix(cca1$xcoef)
V1  <- as.matrix(pc_matrix) %*% as.matrix(cca1$ycoef)

U2 <- as.matrix(fa_matrix)  %*% as.matrix(cca2$xcoef)
V2  <- as.matrix(pc_matrix) %*% as.matrix(cca2$ycoef)

U3 <- as.matrix(fa_matrix) %*% sB$vectors
V3 <- as.matrix(pc_matrix) %*% sA$vectors

# plot correlation between U and V
R1 <- cor(U1,V1)
R2 <- cor(U2,V2)
R3 <- cor(U3,V3)

corrplot(R1,  method = 'number', col = rainbow(1000), title = 'CCA1')
corrplot(R2,  method = 'number', col = rainbow(1000), title = 'CCA2')
corrplot(R3,  method = 'number', col = rainbow(1000), title = 'CCA3')

```

Observaciones:

1. _cc_ tiene la mejor estimación apegada a la teoría (las variables canónicas están intra y extra no correlacionadas salvo $U_{k}$ y $V_{k}$)

2. _cc_ tiene la mejor congruencia entre sus estimaciones de correlaciones entre U y V y $\rho$. En cambio _cancor_ no converge en nada con $\rho_{1}$ y $cor(U_1, V_1)$, sin embargo las demás correlaciones canónicas son congruentes con las correlaciones muestrales entre ellas. Importante notar el caso de hacer el _calculo a mano_, ya que los $\sqrt{\lambda}$ y las correlaciones muestrales entre U y V no empatan absolutamente en nada.

- Correlaciónes entre la primera variable canónica y sus componentes para cada subconjunto.

```{r}

corrplot(cor(U2,fa_matrix),  method = 'number', col = topo.colors(100), title = 'CCA1')
corrplot( cor(V2, pc_matrix),  method = 'number', col = topo.colors(100), title = 'CCA2')


```



Viendo los _loadings_.

Las primeras relaciones canónicas nos muestran lo siguiente:
```{r cca1loadingsss}
z1 <- U2[,1]
z2 <- U2[,2]
w1 <- V2[,1]
w2 <- V2[,2]




data1 <- data.frame(z1, w1)
#scores
ggplot(data = data1, mapping = aes(x = z1, y = w1)) + geom_point() + geom_smooth(method = 'lm')


#relationship with previous campaign
plot(x = z1, y = w1, col = df1[,'poutcome'] + 1)

```
```{r cca1loadings2}
data2 <- data.frame(z2, w2)
#scores
ggplot(data = data2, mapping = aes(x = z2, y = w2)) + geom_point() + geom_smooth(method = 'lm')

#scores with previous outcome
plot(x = z2, y = w2, col = df1[,'poutcome'] + 1)



```

## CCA Banco vs Campaña pasada

```{r}
# set of variables
bank_set <- c('default','balance','housing','loan')
past_campgn_set <- c('contact','days','duration','poutcome')

#select variables
df2 <- df_main[,cbind(bank_set, past_campgn_set)]

#dummies for bank info
df2[,'default'] <- ifelse( df2[,'default'] == 'yes', 1, 0)
df2[,'housing'] <- ifelse( df2[,'housing'] == 'yes', 1, 0)
df2[,'loan'] <- ifelse( df2[,'loan'] == 'yes', 1, 0)

#cols to numeric
df2[,'contact'] <- as.numeric(as.character(df2[,'contact']))




```




```{r}
R2 <- cor(df2)
corrplot(R2, method = 'color', type = 'upper')
corrplot(R2, method = 'number')
```

Vemos también que en este caso las vvariables tienen poca relaición entre ellas


```{r}
# set sets
bank_lis <- c("default",  "balance",  "housing",  "loan")
bank_matrix <- df2[,bank_lis]

pc_lis <- c('contact','days','duration','poutcome')
pc_matrix <- df2[,pc_lis]

#CCA analisis
cca2 <- cancor(x = bank_matrix, y = pc_matrix, xcenter = FALSE, ycenter = FALSE) 

cca2
```


Viendo los _loadings_.

Las primeras relaciones canónicas nos muestran lo siguiente:
```{r cca1loadings}
z1 <- as.matrix(bank_matrix) %*% cca2$xcoef[,1] 
w1 <- as.matrix(pc_matrix) %*% cca2$ycoef[,1] 
data1 <- data.frame(z1, w1)

#plot

#scores
ggplot(data = data1, mapping = aes(x = z1, y = w1)) + geom_point() + geom_smooth(method = 'lm')


#relationship with previous campaign
plot(x = z1, y = w1, col = df2[,'poutcome'] + 1)

```

Las primeras relaciones canónicas nos muestran lo siguiente:
```{r cca11loadings}
z2 <- as.matrix(bank_matrix) %*% cca2$xcoef[,2] 
w2 <- as.matrix(pc_matrix) %*% cca2$ycoef[,2] 
data1 <- data.frame(z2, w2)

#plot

#scores
ggplot(data = data1, mapping = aes(x = z2, y = w2)) + geom_point() + geom_smooth(method = 'lm')


#relationship with previous campaign
plot(x = z2, y = w2, col = df2[,'poutcome'] + 1)

```


# Ejercicio 8: GPA & GMAT

## A) Calcular las medias muestrales y la varianza agrupada

```{r}
#pooled variance

#functions
ni_s <- function(x, population){
  
  pis <- unique(x[,population])
  ni <- c()
  for(pi in pis) 
    ni <- c(ni,length(which(x[,population] == pi)))
  return(ni)
}

#variance
Si_s <- function(x, population){
  Si <- list()
  pis <- unique(x[,population])
  

  for(pi in pis) {
    Si[[pi]] <- cov(x[x[,population] == pi,-population])

  }
  return(Si)
  
}

Spool <-  function(df, population = 3){
  #number of populations
  m <- length(unique(df[,population]))

  #size ni
  ni_vec <- ni_s(df, population)

  #individual variance
  Si_list <- Si_s(df, population)
  
  #pool variance
  #upper part of the fraction
  Spool <- matrix(0,nrow = 2,ncol = 2)

  for(i in 1:m)
    Spool <- Spool +  (ni_vec[i] - 1)[1]  *Si_list[[i]] 
  
  #lower part (constant)
  Spool <- Spool / sum(ni_vec -1)
  
  return(Spool)
}


#read data
df_r <- read.table('T11-6.DAT')
n <- dim(df_r)[1]


#means and pooled variance
# mean
means <- list()
for(i in 1:3) means[[i]] <- colMeans(df_r[ df_r[,3] == i ,c(1,2)])
means

#pooled variance
Sp <- Spool(df_r)

#print means
# knitr::kable(means, col.names = 'population_mean')

cat("\n La varianza agrupada es: ")
Sp



```



## $W$ y $B$, discriminante generalizado. 



```{r}
sample_bet_g <- function(means, mean_o){
  B <- matrix(0, nrow = 2, ncol = 2)
  for(xbar in means){
    B <- B + (xbar - mean_o) %*% t(xbar - mean_o)
  }
  return(B)
}



#overal mean
g <- length(unique(df_r[,3]))         #num of groups
mean_o <- c(0,0)
for(xbar in means)
  mean_o <- mean_o + xbar             #overal mean of groups

# B
B <- sample_bet_g(means, mean_o)

# W
W <- (n - g)* Sp
Winv <- solve(W)
# eigen W-1B
sWB <-eigen(Winv%*% B)

B
Winv
sWB
```

Clasificaremos el siguiente alumno $x_{0}^{T} = [3.21 \quad 497]$.

```{r}
#new obs
x0 <- c(3.21, 497)

# discriminants

#first we make unite variance 
v1 <- t(as.matrix(sWB$vectors[,1])) %*% Sp %*% as.matrix(sWB$vectors[,1])
v2 <- t(as.matrix(sWB$vectors[,2])) %*% Sp %*% as.matrix(sWB$vectors[,2])

a1 <- as.matrix(sWB$vectors[,1]) / v1[1]
a2 <- as.matrix(sWB$vectors[,2]) / v2[1]

# discriminants
y <- t(cbind(a1,a2)) %*% x0
mu_y_p1 <- t(cbind(a1,a2)) %*% means[[1]]
mu_y_p2 <- t(cbind(a1,a2)) %*% means[[2]]
mu_y_p3 <- t(cbind(a1,a2)) %*% means[[3]]


#clasiffy
score_p1 <- t(y - mu_y_p1) %*% (y - mu_y_p1)
score_p2 <- t(y - mu_y_p2) %*% (y - mu_y_p2)
score_p3 <- t(y - mu_y_p3) %*% (y - mu_y_p3)

score_p1
score_p2
score_p3

```

Vemos que el score más pequeño es el de la población $\prod_{3}$ , por lo que _clasificamos_ al estudiante nuevo $x_0$ como alguien en el _border line_ .

La clasificación _sí_ coincide con la del libro.





























